# app/tasks/import_grille.py

# Using the configured Celery app instance is crucial for correct broker connection
from src.celery_app import celery
from openai import OpenAI
import logging

from flask import current_app

logger = logging.getLogger(__name__)

# Define the JSON schema outside the task function for clarity
GRILLE_SCHEMA = {
    "type": "object",
    "required": ["programme", "sessions"],
    "properties": {
        "programme": {
            "type": "string",
            "description": "Nom du programme d'√©tudes."
        },
        "sessions": {
            "type": "array",
            "description": "Liste des sessions (semestres ou p√©riodes) incluses dans le programme.",
            "items": {
                "type": "object",
                "required": ["numero_session", "cours"],
                "properties": {
                    "numero_session": {
                        "type": "number",
                        "description": "Num√©ro de session sous forme d'un chiffre (ex.: 1, 2, 3)."
                    },
                    "cours": {
                        "type": "array",
                        "description": "Liste des cours offerts pendant la session.",
                        "items": {
                            "type": "object",
                            "required": [
                                "code_cours", "titre_cours", "heures_theorie",
                                "heures_labo", "heures_maison", "prerequis", "corequis"
                            ],
                            "properties": {
                                "code_cours": {"type": "string", "description": "Code du cours (ex. 243-1J5-LI)."},
                                "titre_cours": {"type": "string", "description": "Intitul√© du cours."},
                                "heures_theorie": {"type": "number", "description": "Nombre d'heures de th√©orie par semaine."},
                                "heures_labo": {"type": "number", "description": "Nombre d'heures de laboratoire par semaine."},
                                "heures_maison": {"type": "number", "description": "Nombre d'heures de travail √† la maison par semaine."},
                                "prerequis": {
                                    "type": "array",
                                    "description": "Liste des cours pr√©alables n√©cessaires.",
                                    "items": {
                                        "type": "object",
                                        "required": ["code_cours", "pourcentage_minimum"],
                                        "properties": {
                                            "code_cours": {"type": "string", "description": "Code du cours pr√©alable."},
                                            # Use number, default to 0 if not applicable/found
                                            "pourcentage_minimum": {"type": "number", "description": "Note minimale requise pour ce pr√©alable (0 si non sp√©cifi√©)."}
                                        },
                                        "additionalProperties": False
                                    }
                                },
                                "corequis": {
                                    "type": "array",
                                    "description": "Liste des codes des cours corequis.",
                                    "items": {
                                        "type": "string",
                                        "description": "Code d‚Äôun cours corequis."
                                    }
                                }
                            },
                            "additionalProperties": False # Disallow extra fields per course
                        }
                    }
                },
                "additionalProperties": False # Disallow extra fields per session
            }
        }
    },
    "additionalProperties": False # Disallow extra fields at the top level
}


@celery.task(bind=True)
def extract_grille_from_pdf_task(self, pdf_path, model=None, openai_key=None):
    """
    T√¢che Celery qui :
     1. Charge un fichier PDF via OpenAI.
     2. Utilise client.responses.create() pour extraire la grille de cours
        au format JSON selon un sch√©ma sp√©cifi√©.

    :param pdf_path: Chemin vers le fichier PDF √† traiter.
    :param model: Mod√®le OpenAI √† utiliser.
    :param openai_key: Cl√© API OpenAI de l'utilisateur.
    :return: Dictionnaire avec le r√©sultat ou un message d'erreur.
    """
    task_id = self.request.id
    if model is None:
        model = current_app.config.get("OPENAI_MODEL_EXTRACTION")
    logger.info(f"[{task_id}] Starting task for PDF: {pdf_path} (model: {model})")

    if not openai_key:
        logger.error(f"[{task_id}] Missing OpenAI API Key.")
        # Fail the task if the key is missing
        # self.update_state(state='FAILURE', meta={'exc_type': 'ValueError', 'exc_message': 'Missing API Key'})
        # raise ValueError("Missing OpenAI API Key")
        return {"status": "error", "message": "Cl√© API OpenAI manquante."}

    try:
        # Instanciation du client OpenAI
        client = OpenAI(api_key=openai_key)

        logger.info(f"[{task_id}] Uploading PDF file from {pdf_path}")
        # Chargement du fichier PDF dans OpenAI
        with open(pdf_path, "rb") as f:
            file_response = client.files.create(
                file=f,
                purpose="user_data"
            )
        logger.info(f"[{task_id}] File uploaded, file_id: {file_response.id}")

        # Pr√©paration du prompt textuel
        prompt_text = (
            "Vous √™tes un assistant sp√©cialis√© dans l‚Äôextraction structur√©e de donn√©es √† partir de documents acad√©miques.\n\n"
            "Votre t√¢che est d‚Äôextraire uniquement les cours de la formation sp√©cifique pr√©sents dans le document fourni, "
            "et de les organiser selon le sch√©ma JSON strict 'grille_de_cours' fourni.\n\n"
            "üîí Contraintes obligatoires :\n"
            "- Respectez strictement le sch√©ma JSON fourni. Aucune propri√©t√© additionnelle ou omission ne sera tol√©r√©e.\n"
            "- Tous les champs requis doivent √™tre pr√©sents et respecter leur type (cha√Æne, nombre, tableau, etc.).\n"
            "- La sortie doit √™tre un objet JSON valide, correspondant √† la structure exacte attendue.\n"
            "- Ne produisez aucun texte explicatif ou commentaire en dehors du JSON.\n"
            "- Lorsqu‚Äôun cours pr√©sente un format abr√©g√© comme 2-3-2, il repr√©sente : 2 heures de th√©orie, 3 heures de laboratoire, 2 heures de travail √† la maison. D√©composez ces valeurs dans les champs correspondants.\n\n"
            "üß† R√®gles d‚Äôinterpr√©tation sp√©cifiques :\n"
            "- Les corequis sont g√©n√©ralement indiqu√©s au-dessus ou √† c√¥t√© du nom du cours correspondant. Associez-les correctement (inclure seulement les codes de cours corequis).\n"
            "- Ignorez toute occurrence de la mention ¬´ (ASP) ¬ª dans les titres de cours.\n"
            "- N‚Äôincluez aucun cours de formation g√©n√©rale (ex: √âducation Physique, Anglais, Philosophie, Fran√ßais) ou compl√©mentaire.\n"
            "- Si un pr√©requis a une note minimale sp√©cifi√©e (ex: '60%'), extrayez cette valeur num√©rique pour 'pourcentage_minimum', sinon mettez 0.\n"
            "- Extrayez le nom du programme et structurez les cours par session comme indiqu√© dans le document."
        )

        logger.info(f"[{task_id}] Calling OpenAI responses.create API, model: {model}")
        # Appel de l'API responses avec le fichier et un prompt textuel.
        response = client.responses.create(
            model=model,
            input=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "input_file",
                            "file_id": file_response.id # CORRECTED: file_id is direct key
                        },
                        {
                            "type": "input_text",
                            "text": prompt_text
                        }
                    ]
                }
            ],
            # Define the expected output structure and constraints
            text={
                "format": {
                    "type": "json_schema",
                    "name": "grille_de_cours", # Must match the name in the schema itself if relevant
                    "strict": True, # Enforce strict adherence
                    "schema": GRILLE_SCHEMA
                }
            },
            # Parameters to control generation
            temperature=0.1, # Lower temperature for more deterministic output
            max_output_tokens=4096, # Adjust as needed based on typical output size
            top_p=1,
            store=True # Store the interaction if needed for review
            # 'reasoning': {}, # Optional: Add reasoning instructions if needed
            # 'tools': [], # Optional: Add tools if needed
        )

        logger.info(f"[{task_id}] OpenAI response received successfully.")

        # Consider adding validation here to ensure output_text is valid JSON
        # import json
        # try:
        #     json.loads(response.output_text)
        #     logger.info(f"[{task_id}] Output is valid JSON.")
        # except json.JSONDecodeError:
        #     logger.error(f"[{task_id}] Output is NOT valid JSON: {response.output_text}")
        #     # Handle invalid JSON case

        # Clean up the uploaded file from OpenAI storage (optional but good practice)
        try:
            logger.info(f"[{task_id}] Deleting uploaded file: {file_response.id}")
            client.files.delete(file_response.id)
            logger.info(f"[{task_id}] Successfully deleted file: {file_response.id}")
        except Exception as delete_err:
            # Log deletion error but don't fail the main task because of it
            logger.warning(f"[{task_id}] Failed to delete file {file_response.id}: {delete_err}")


        return {
            "status": "success",
            "result": response.output_text, # This should be the JSON string
            "usage": {
                "input_tokens": getattr(response.usage, 'input_tokens', 0),
                "output_tokens": getattr(response.usage, 'output_tokens', 0)
            },
            # Page standard de validation/confirmation de l'import
            "validation_url": f"/confirm_grille_import/{task_id}"
        }

    except Exception as e:
        # Log the full error and traceback
        logger.error(f"[{task_id}] Error in extract_grille_from_pdf_task: {e}", exc_info=True)

        # Optionally update Celery task state to FAILURE
        # self.update_state(state='FAILURE', meta={'exc_type': type(e).__name__, 'exc_message': str(e)})

        # Return error status
        # Check if the error is from OpenAI API and try to extract more details
        error_message = str(e)
        if hasattr(e, 'message'): # Handle potential OpenAI specific error structure
            error_message = e.message
        elif hasattr(e, 'response') and hasattr(e.response, 'text'):
             error_message = f"{str(e)} - Response: {e.response.text}"

        return {"status": "error", "message": error_message}
